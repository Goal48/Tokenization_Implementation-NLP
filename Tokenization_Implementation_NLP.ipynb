{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtDOoYBXkokZH1wBsxS03I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Goal48/Tokenization_Implementation-NLP/blob/main/Tokenization_Implementation_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdVNbXz13v1u",
        "outputId": "8cd3a299-914d-4048-eba6-31c0d2e6d0f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = \"\"\"Hi I am Pius Dutta.\n",
        "I am studying the NLP course form Krish Naik. What a wonderfull course!\"\"\""
      ],
      "metadata": {
        "id": "Fujmmn5K4MA_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punktab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF9khrzy6R6c",
        "outputId": "f1b7eccc-785f-4bd7-caa8-a2aaf88b54ae"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Error loading punktab: Package 'punktab' not found in\n",
            "[nltk_data]     index\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenization (Paragraph -->> Sentence)\n",
        "from nltk.tokenize import sent_tokenize\n",
        "document = sent_tokenize(corpus)\n",
        "print(document)\n",
        "type(document)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlVSeCE354-5",
        "outputId": "383bbd94-0f34-43f8-dbb0-063ecdcd5d59"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi I am Pius Dutta.', 'I am studying the NLP course form Krish Naik.', 'What a wonderfull course!']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Tokenization (Paragraph -->> words)/(Sentence -->> Words)\n",
        "from nltk.tokenize import word_tokenize ## wordpuct_tokenize --> used for it also separeted puncuations\n",
        "words = word_tokenize(corpus)\n",
        "print(words)\n",
        "type(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50qvqc466M8l",
        "outputId": "bb451ac5-237a-494f-8c15-4e1f1c2e1193"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi', 'I', 'am', 'Pius', 'Dutta', '.', 'I', 'am', 'studying', 'the', 'NLP', 'course', 'form', 'Krish', 'Naik', '.', 'What', 'a', 'wonderfull', 'course', '!']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordDetokenizer\n",
        "tokenizer = TreebankWordDetokenizer()\n",
        "tokenizer.tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "bQph6JF771O9",
        "outputId": "3d6797a6-fc2d-4140-d64b-6ddf831e9985"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'H i   I   a m   P i u s   D u t t a . \\n I   a m   s t u d y i n g   t h e   N L P   c o u r s e   f o r m   K r i s h   N a i k .   W h a t   a   w o n d e r f u l l   c o u r s e!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ProterStemmer"
      ],
      "metadata": {
        "id": "gRZRCn5dOm60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = ['eating','eaten','written','writer','removed']"
      ],
      "metadata": {
        "id": "bCqUvdJb-VDm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "for word in words :\n",
        "  print(word + \" : \" + stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIBk1mm0O9rq",
        "outputId": "3dfc3274-9937-4f41-e956-abf0e46968c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating : eat\n",
            "eaten : eaten\n",
            "written : written\n",
            "writer : writer\n",
            "removed : remov\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RegexpStemming"
      ],
      "metadata": {
        "id": "yFTUBnwlSKCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Group = ['eating','eaten','written','remove']"
      ],
      "metadata": {
        "id": "hDqOXM49SgJ6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "stemmer = RegexpStemmer('ing$|en$|ed$', min=4)\n",
        "for word in Group :\n",
        "  print(word + \" : \" + stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu538zohPOzo",
        "outputId": "99130607-fd36-4e2a-b982-f536870f3d19"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating : eat\n",
            "eaten : eat\n",
            "written : writt\n",
            "remove : remove\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1kBlOaHISZzl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}